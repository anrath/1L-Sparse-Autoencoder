sbatch slurm.slurm
squeue -u kl5sq

/u/kl5sq/.conda/envs/sparse/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/u/kl5sq/nlp-project/1L-Sparse-Autoencoder/train.py", line 5, in <module>
    buffer = Buffer(cfg)
  File "/u/kl5sq/nlp-project/1L-Sparse-Autoencoder/utils.py", line 237, in __init__
    self.refresh()
  File "/u/kl5sq/.conda/envs/sparse/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/u/kl5sq/nlp-project/1L-Sparse-Autoencoder/utils.py", line 242, in refresh
    with torch.autocast("cuda", torch.bfloat16):
  File "/u/kl5sq/.conda/envs/sparse/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 305, in __init__
    raise RuntimeError(
RuntimeError: Current CUDA Device does not support bfloat16. Please switch dtype to float16.

sinfo -o "%N %G"
        NODELIST GRES
        affogato[01-10],cortado[01-10],coursesrv[06-07],doppio[01-05],epona,heartpiece,hydro,lynx[08-09],optane01,panther01,puma01,slurm[1-5] (null)
        jaguar05 gpu:quadro_rtx_4000:4(S:0)
        jaguar06 gpu:a40:2(S:0-1)
        lynx01 gpu:nvidia_titan_xp:4(S:0-1)
        lynx[05-07] gpu:tesla_p100-pcie-12gb:4(S:0-1)
        adriatic[01-06] gpu:quadro_rtx_4000:4(S:0-1)
        jaguar01 gpu:nvidia_a40:4(S:0-1)
        jaguar02 gpu:nvidia_a16:8(S:0-1)
        jaguar04 gpu:a40:4(S:0-1)
        lynx10 gpu:geforce_gtx_1080_ti:1(S:0),gpu:geforce_gtx_1080:2(S:1)
        lynx11 gpu:nvidia_titan_x:3(S:0-1),gpu:nvidia_geforce_gtx_1080:1(S:1)
        lynx12 gpu:nvidia_titan_x:4(S:0-1)
        ristretto01 gpu:nvidia_geforce_gtx_1080_ti:8(S:0-1)
        sds[01-02] gpu:nvidia_rtx_a4000:4(S:0-1)
        cheetah01 gpu:nvidia_a100-pcie-40gb:4(S:0-1)
        cheetah[02-03] gpu:nvidia_geforce_rtx_2080_ti:2(S:0-1)
        cheetah04 gpu:a100:4(S:0-1)
        jaguar03 gpu:nvidia_rtx_a4500:8(S:0-1)
        lotus gpu:quadro_rtx_6000:8(S:0-1)
        affogato[11-15],ai[01-04,06-09],lynx[02-04] gpu:nvidia_geforce_gtx_1080_ti:4(S:0-1)
        ai[05,10] gpu:nvidia_geforce_gtx_1080:4(S:0-1)
        jinx[01-02] gpu:nvidia_geforce_gtx_1080:2(S:0)
        titanx[01-05] gpu:nvidia_titan_x:1(S:0)
        cheetah05 gpu:a100:4(S:1)
        serval01 gpu:nvidia_h100_80gb_hbm3:4(S:0-1)